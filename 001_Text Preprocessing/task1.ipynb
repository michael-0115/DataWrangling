{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "\n",
    "### Introduction\n",
    "In this assignment, I am going to use some data wrangling techniques to do the text preprocessing for the data been provided in XML format which contains 2,500 patents and to convert the data into a proper format for information references. In the given data, there have information include publication reference, application reference, abstract, description, claims, citations, etc. \n",
    "\n",
    "And the text preprocessing for this assignment focus on patents information collocation including International Patent Classification (IPC) code and abstract, also the patents' citation network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 tasks wirtten in seperated ipynb files in Python 2.0 by using Jupytur notebook for this Assignment of Text Preprocessing which includes:\n",
    "\n",
    "1. Extract the hierarchical IPC code\n",
    "2. Extract the citation network\n",
    "3. Identify number of patent citation\n",
    "4. Extract and preprocess abstracts\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file belongs the task 1.  \n",
    "\n",
    "# Extract the hierarchical IPC code\n",
    "\n",
    "To extract the hierarchical IPC codes for all the patents in the XML file which contain contains 2,500 patents in total and store them in output file \"classification.txt\" with the following information in the below format: \n",
    "                \n",
    "* patent’s_ID:Section,Class,Subclass,Main_group,Subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Use BeautifulSoup to extract information from the XML file.\n",
    "\n",
    "When first time tried to open the XML file and parse the data to jupyter book by using BeautifulSoup, lxml’s XML parser, it turns out to be that the parser cannot parser all the data from the file and returned some error information. After examining the original XML file by editor, I found out that the file is not a well-formed XML file, which instead the file itself contains 2,500 individual XML files in it. So, the lxml’s XML parser can only successfully parses the first section as it recognizes the section that belong to a well-formed XML file structure.\n",
    "\n",
    "The way to solve this problem is to open the file directly without parsing it and do the edition of the original files to the correct structure and save each patent to the list separately before using any parser. Or use Python’s html.parser with BeautifulSoup, it can parse the so call un-well-formed XML file without error. And I am going the use the Python’s html.parser to parse and extract data from XML files with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open(\"patents.xml\"),\"html.parser\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Examining the hierarchy of the xml file and obtain the information we need.\n",
    "\n",
    "By examining the hierarchy of the xml file, we noted that the information we would like to extract is stored in the following tags:\n",
    "\n",
    " * for patent's ID:  \n",
    " \n",
    "        publication-reference > doc-number\n",
    "         * the citing patent id is located under tags publication-reference > doc-number\n",
    " \n",
    " * for patent's Section,Class,Subclass,Main_group and Subgroup:\n",
    "                     \n",
    "        classification-ipcr> section \n",
    "        classification-ipcr> class \n",
    "        classification-ipcr> main-group \n",
    "        classification-ipcr> subgroup \n",
    "         * classification information for patents are under tag classification-ipcr)\n",
    "        \n",
    "###### 3.1 To get the patent_id and return to a list: patents_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PP021722',\n",
       " u'RE042159',\n",
       " u'RE042170',\n",
       " u'07891018',\n",
       " u'07891019',\n",
       " u'07891020',\n",
       " u'07891021',\n",
       " u'07891023',\n",
       " u'07891025',\n",
       " u'07891026']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication_reference_tags = soup.find_all(\"publication-reference\")\n",
    "patents_id = [item.find(\"doc-number\").string for item in publication_reference_tags] \n",
    "patents_id[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.2 To find the \"section\",\"class\",\"subclass\",\"main-group\"and \"subgroup\" under patents and store to a list : patents_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'A', u'01', u'H', u'5', u'00'],\n",
       " [u'G', u'01', u'B', u'7', u'14'],\n",
       " [u'G', u'06', u'F', u'11', u'00'],\n",
       " [u'A', u'41', u'D', u'13', u'00'],\n",
       " [u'A', u'41', u'D', u'13', u'00'],\n",
       " [u'A', u'41', u'D', u'13', u'00'],\n",
       " [u'A', u'62', u'B', u'17', u'00'],\n",
       " [u'A', u'41', u'F', u'19', u'00'],\n",
       " [u'A', u'61', u'F', u'9', u'02'],\n",
       " [u'A', u'41', u'D', u'13', u'00']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_list = [\"section\",\"class\",\"subclass\",\"main-group\",\"subgroup\"]\n",
    "\n",
    "patents_info = []\n",
    "classification_ipcr_tags = soup.find_all(\"classification-ipcr\")\n",
    "for item in classification_ipcr_tags:\n",
    "    temp = []\n",
    "    for tag in tags_list:\n",
    "        temp.append(item.find(tag).string)\n",
    "    patents_info.append(temp)      \n",
    "    \n",
    "patents_info[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Data formatting for the collected data and output to file.\n",
    "\n",
    "A patent list which contains all the 2,500 patents ID and another information list that contains information of the patent including \"section\", \"class\", \"subclass\", \"main-group\" and \"subgroup\" have been generated. The patents in the patent list is in the same position of the information list. \n",
    "\n",
    "###### 4.1 Combine both lists to a list so each item in the new list store the patent's id and its classification data as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'PP021722', [u'A', u'01', u'H', u'5', u'00']],\n",
       " [u'RE042159', [u'G', u'01', u'B', u'7', u'14']],\n",
       " [u'RE042170', [u'G', u'06', u'F', u'11', u'00']],\n",
       " [u'07891018', [u'A', u'41', u'D', u'13', u'00']],\n",
       " [u'07891019', [u'A', u'41', u'D', u'13', u'00']],\n",
       " [u'07891020', [u'A', u'41', u'D', u'13', u'00']],\n",
       " [u'07891021', [u'A', u'62', u'B', u'17', u'00']],\n",
       " [u'07891023', [u'A', u'41', u'F', u'19', u'00']],\n",
       " [u'07891025', [u'A', u'61', u'F', u'9', u'02']],\n",
       " [u'07891026', [u'A', u'41', u'D', u'13', u'00']]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_scheme = []\n",
    "for i in range (len(patents_id)):\n",
    "    classification_scheme.append([patents_id[i], patents_info[i]])\n",
    "classification_scheme[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2 After the final list been setted up. Rearrange the sequence of the patents in the list by sort function and to write item to the file line by line as task required output format:\n",
    "* patent’s_ID:Section,Class,Subclass,Main_group,Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_scheme.sort()\n",
    "\n",
    "output_file = open (\"classification.txt\", \"w+\")   \n",
    "\n",
    "for item in classification_scheme:\n",
    "    line = item[0]+\":\"+ \",\".join(item[1])+\"\\n\"\n",
    "    output_file.write(line) \n",
    "\n",
    "    \n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
